{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image, ImageChops\n",
    "import operator\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from skimage.transform import resize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "train_path = 'dataset'\n",
    "l = []\n",
    "\n",
    "for subpath in tqdm(os.listdir(train_path)):\n",
    "    for file in os.listdir(train_path+'/'+subpath):\n",
    "        path = train_path+'/'+subpath+'/'+file\n",
    "        im = Image.open(path)\n",
    "        im_arr = (np.array(ImageChops.invert(Image.open(path)).resize((28,28)))/255).flatten()\n",
    "        im_arr = np.append(im_arr, int(subpath))\n",
    "        l.append(im_arr)\n",
    "\n",
    "dataset = pd.DataFrame(l)\n",
    "dataset = dataset.rename(columns={784:'label'})\n",
    "dataset.to_csv('dataset.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({7.0: 818,\n",
       "         8.0: 816,\n",
       "         9.0: 820,\n",
       "         6.0: 813,\n",
       "         4.0: 815,\n",
       "         1.0: 810,\n",
       "         5.0: 826,\n",
       "         2.0: 816,\n",
       "         3.0: 799,\n",
       "         0.0: 795})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('dataset.csv')\n",
    "X = np.array(dataset.drop('label',axis=1))\n",
    "y = np.array(dataset.label)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print('training set population',Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > training classifier on training set:\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    8.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > testing classifier on testing set:\n",
      "\n",
      " > Best grid search:\n",
      "{'LDA__solver': 'svd', 'SKB__k': 'all'}\n",
      "\n",
      " > Classifier dumped\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96       221\n",
      "         1.0       0.80      0.97      0.88       206\n",
      "         2.0       0.98      0.94      0.96       200\n",
      "         3.0       0.96      0.95      0.96       217\n",
      "         4.0       0.98      0.93      0.95       201\n",
      "         5.0       0.95      0.93      0.94       190\n",
      "         6.0       0.96      0.93      0.95       203\n",
      "         7.0       0.98      0.93      0.96       198\n",
      "         8.0       0.95      0.95      0.95       200\n",
      "         9.0       0.97      0.91      0.94       196\n",
      "\n",
      "    accuracy                           0.94      2032\n",
      "   macro avg       0.95      0.94      0.94      2032\n",
      "weighted avg       0.95      0.94      0.94      2032\n",
      "\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# cross-validator : Stratified Shuffle Split \n",
    "sss = StratifiedShuffleSplit(n_splits = 2, test_size = 0.2, random_state = 42) \n",
    "\n",
    "# Functions to be used in the pipeline\n",
    "skb = SelectKBest(f_classif)\n",
    "\n",
    "### Define classifier ###\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "\n",
    "# definition of the pipeline\n",
    "pipeline = Pipeline(steps = [\n",
    "    ('SKB',skb),\n",
    "    ('LDA',clf)\n",
    "])   \n",
    "\n",
    "# parameters to tune \n",
    "param_grid = {\n",
    "    'SKB__k':['all'],\n",
    "    'LDA__solver':['svd'],\n",
    "} \n",
    "\n",
    "# exhaustive search over specified parameter\n",
    "grid = GridSearchCV(pipeline, param_grid, verbose = 1, cv = sss)\n",
    "\n",
    "# training classifier\n",
    "print (\" > training classifier on training set:\")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# best classifier using the cross-validator and the Stratified Shuffle Split \n",
    "clf = grid.best_estimator_\n",
    "\n",
    "# predicition with the classifier\n",
    "print (\" > testing classifier on testing set:\")\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print grid parameters\n",
    "print (\"\\n > Best grid search:\")\n",
    "print (grid.best_params_)\n",
    "\n",
    "# dump classifier in a pickle file\n",
    "print (\"\\n > Classifier dumped\")\n",
    "with open(\"digit_classifier.pkl\", 'wb') as fid:\n",
    "    pk.dump(clf, fid)\n",
    "    \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
